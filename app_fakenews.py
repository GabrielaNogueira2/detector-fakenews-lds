import streamlit as st
import pandas as pd
import numpy as np
import joblib
import re
import string
import os
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(
    page_title="Detector de Fake News - LDS",
    page_icon="üïµÔ∏è‚Äç‚ôÄÔ∏è",
    layout="wide"
)

# --- ESTILOS CUSTOMIZADOS (CSS) ---
st.markdown("""
    <style>
    .main-header {font-size: 2.5rem; color: #FF4B4B; text-align: center; margin-bottom: 1rem;}
    .sub-text {text-align: center; color: #555;}
    .result-box {padding: 20px; border-radius: 10px; text-align: center; font-size: 24px; font-weight: bold;}
    .safe {background-color: #D4EDDA; color: #155724; border: 2px solid #C3E6CB;}
    .fake {background-color: #F8D7DA; color: #721C24; border: 2px solid #F5C6CB;}
    </style>
""", unsafe_allow_html=True)

# --- FUN√á√ïES DE LIMPEZA (Baseadas no seu Notebook) ---
def wordopt(text):
    text = text.lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub("\\W"," ",text) 
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    return text

# --- CACHE E TREINAMENTO DO MODELO ---
# Usamos @st.cache_resource para n√£o treinar toda vez que a p√°gina recarregar
@st.cache_resource
def train_model(uploaded_true, uploaded_fake):
    """
    Treina o modelo se os arquivos forem fornecidos.
    Retorna o pipeline treinado (Vetorizador + Modelo).
    """
    try:
        # Carregando dados
        df_true = pd.read_csv(uploaded_true)
        df_fake = pd.read_csv(uploaded_fake)
        
        # Criando coluna alvo (Target)
        df_true["class"] = 1 # Not√≠cia Real
        df_fake["class"] = 0 # Fake News
        
        # Juntando os dataframes (Conforme seu notebook)
        # O notebook remove as √∫ltimas 10 linhas para teste manual, 
        # mas aqui usaremos tudo para treinar o "motor" do site.
        df_merge = pd.concat([df_fake, df_true], axis=0)
        
        # Pr√©-processamento essencial (Cria√ß√£o da coluna Full Text)
        df_merge["full_text"] = df_merge["title"] + " " + df_merge["text"]
        df_merge["full_text"] = df_merge["full_text"].apply(wordopt)
        
        # Definindo X e Y
        X = df_merge["full_text"]
        y = df_merge["class"]
        
        # Divis√£o Treino/Teste
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
        
        # Pipeline: Vetoriza√ß√£o -> Classifica√ß√£o
        # Pipeline garante que o texto novo sofra as mesmas transforma√ß√µes do treino
        pipeline = Pipeline([
            ('tfidf', TfidfVectorizer()),
            ('clf', LogisticRegression())
        ])
        
        pipeline.fit(X_train, y_train)
        
        # Valida√ß√£o r√°pida
        pred = pipeline.predict(X_test)
        acc = accuracy_score(y_test, pred)
        
        return pipeline, acc

    except Exception as e:
        return None, str(e)

# --- BARRA LATERAL (SIDEBAR) ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2910/2910768.png", width=100)
    st.title("Sobre o Projeto")
    st.markdown("**Liga de Data Science**")
    
    st.markdown("### Equipe T√©cnica:")
    st.markdown("""
    - **Jo√£o Pacolla:** Estrutura/Dados
    - **Matheus Schartner:** Limpeza/NLP
    - **Victor Godoy:** Modelagem
    - **Renan Ribeiro:** Avalia√ß√£o
    - **Gabriela Nogueira:** Documenta√ß√£o
    """)
    
    st.info("""
    **Contexto:**
    Este projeto utiliza Processamento de Linguagem Natural (NLP) para classificar not√≠cias 
    baseando-se no estilo de escrita e formata√ß√£o (N√≠vel 1).
    """)

    st.markdown("---")
    st.subheader("‚öôÔ∏è Configura√ß√£o do Modelo")
    
    # Upload dos datasets caso o modelo n√£o exista na mem√≥ria
    st.markdown("Para o site funcionar, precisamos treinar o modelo. Fa√ßa upload dos CSVs originais (True.csv e Fake.csv).")
    upl_true = st.file_uploader("Carregar True.csv", type="csv")
    upl_fake = st.file_uploader("Carregar Fake.csv", type="csv")

# --- √ÅREA PRINCIPAL ---

st.markdown('<div class="main-header">Detector de Fake News üá∫üá∏</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-text">Insira o t√≠tulo e o texto da not√≠cia para verificar sua veracidade.</div>', unsafe_allow_html=True)

st.write("") # Espa√ßamento

# L√≥gica de Inicializa√ß√£o
model = None
accuracy = 0

if upl_true and upl_fake:
    with st.spinner('Treinando o modelo com seus dados... aguarde um momento...'):
        model, accuracy = train_model(upl_true, upl_fake)
    
    if isinstance(model, str): # Se retornou string, √© erro
        st.error(f"Erro ao treinar: {model}")
    else:
        st.success(f"Modelo treinado com sucesso! Acur√°cia estimada: {accuracy:.2%}")

else:
    st.warning("‚ö†Ô∏è Por favor, fa√ßa o upload dos arquivos `True.csv` e `Fake.csv` na barra lateral para ativar o sistema.")

# Formul√°rio de Entrada
with st.form("prediction_form"):
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.write("### 1. T√≠tulo")
        title_input = st.text_area("Cole o t√≠tulo aqui", height=150, placeholder="Ex: Trump Says...")
    
    with col2:
        st.write("### 2. Corpo da Not√≠cia")
        text_input = st.text_area("Cole o texto completo aqui", height=150, placeholder="Ex: Washington (Reuters) - ...")
    
    submit_btn = st.form_submit_button("üîç Verificar Veracidade", type="primary")

# L√≥gica de Predi√ß√£o
if submit_btn:
    if model is None:
        st.error("O modelo ainda n√£o foi treinado. Use a barra lateral para carregar os dados.")
    elif not title_input and not text_input:
        st.warning("Por favor, preencha pelo menos um dos campos.")
    else:
        # Prepara o texto (Mesma l√≥gica do notebook: Title + Text)
        full_text_input = str(title_input) + " " + str(text_input)
        processed_text = wordopt(full_text_input)
        
        # Predi√ß√£o
        prediction = model.predict([processed_text])[0]
        probabilidade = model.predict_proba([processed_text]).max()
        
        st.markdown("---")
        st.subheader("Resultado da An√°lise:")
        
        if prediction == 1:
            st.markdown(
                f'<div class="result-box safe">‚úÖ NOT√çCIA VERDADEIRA (REAL)<br><span style="font-size:16px">Confian√ßa do modelo: {probabilidade:.2%}</span></div>', 
                unsafe_allow_html=True
            )
            st.balloons()
        else:
            st.markdown(
                f'<div class="result-box fake">üö® FAKE NEWS DETECTADA<br><span style="font-size:16px">Confian√ßa do modelo: {probabilidade:.2%}</span></div>', 
                unsafe_allow_html=True
            )
            
        # Explicabilidade Simples (Insights do Relat√≥rio)
        with st.expander("‚ÑπÔ∏è Entenda como o modelo decidiu"):
            st.write("""
            O modelo analisa padr√µes lingu√≠sticos. Segundo o relat√≥rio do projeto (Sprint 4):
            - **Not√≠cias Reais:** Tendem a ter linguagem formal, citar ag√™ncias (ex: Reuters) e ter estrutura padr√£o.
            - **Fake News:** Costumam usar linguagem sensacionalista, muitos adjetivos e formata√ß√£o irregular.
            """)
            st.write(f"**Texto processado que o modelo 'leu':**")
            st.caption(processed_text[:500] + "...")

# Rodap√©
st.markdown("---")
st.markdown("Desenvolvido para o Projeto DS - An√°lise de Fake News Americanas")